{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from numpy import linalg #SVD\n",
    "import screed \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statistics\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "random_seed = 600\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "#---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPRIMIR RESULTADOS DE MÉTRICAS----------------------------------------------------------------\n",
    "def print_metrics(metrics, model_name, db_selection, folder): \n",
    "\n",
    "    db_name = \"nf\" if int(db_selection) == 0 else \"full\"\n",
    "    \n",
    "    db = \"No Feature\" if int(db_selection) == 0 else \"Full\"\n",
    "    print(\"Database: \", db,\" \", model_name,\" \\n\")\n",
    "    print('-'*50)\n",
    "    if (db_selection == 0):\n",
    "        print('Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder')\n",
    "    elif (db_selection == 1):\n",
    "        print('Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)')\n",
    "    print('-'*50)\n",
    "    print('Accuracy Training: ', statistics.mean(metrics[\"accuracy_train\"])*100)\n",
    "    print('Accuracy Testing: ', statistics.mean(metrics[\"accuracy_test\"])*100)\n",
    "    print('Precision: ', statistics.mean(metrics[\"precision\"])*100)\n",
    "    print('Sensitivity: ', statistics.mean(metrics[\"sensitivity\"])*100) \n",
    "    print('Specificity: ', statistics.mean(metrics[\"specificity\"])*100)\n",
    "    print('f_1 Score: ', statistics.mean(metrics[\"f1\"])*100)\n",
    "    print('MCC: ', statistics.mean(metrics[\"mcc\"])*100) \n",
    "    print('AUC Score: ', statistics.mean(metrics[\"auc\"])*100) \n",
    "    print('MSE: ', statistics.mean(metrics[\"mse\"]))\n",
    "    print('Mis-Classification: ', statistics.mean(metrics[\"misc\"])) \n",
    "\n",
    "    #Mostrar más decimales en DF\n",
    "    pd.set_option(\"display.precision\", 15)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    metrics_model = [metrics[\"accuracy_train\"], metrics[\"accuracy_test\"], metrics[\"precision\"], \n",
    "                    metrics[\"sensitivity\"], metrics[\"specificity\"], metrics[\"f1\"], metrics[\"mcc\"], metrics[\"auc\"], \n",
    "                     metrics[\"mse\"], metrics[\"misc\"]]\n",
    "    metrics_m = pd.DataFrame(metrics_model, columns = ['1', '2','3', '4', '5'],\n",
    "                index = ['Accuracy Training','Accuracy Test', 'Precision', 'Sensitivity', 'Specificity', 'f_1 Score', \n",
    "                         'MCC', 'AUC Score',  'MSE', 'Mis-Classification'])\n",
    "    metrics_m[:-2] = metrics_m[:-2]*100\n",
    "    \n",
    "    print(metrics_m)\n",
    "\n",
    "# Construcción de los Datasets----------------------------------------------------------------\n",
    "def build_datasets(df_model):\n",
    "    X = df_model.iloc[:, :-1] # Secuencias\n",
    "\n",
    "    y = df_model.iloc[:,-1] # Clases\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def confusion_metrics(conf_matrix):\n",
    "    # Guardar la matriz de confusión y la divida en 4 piezas\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "\n",
    "    # Calcular Precisión\n",
    "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "    # Calcular mis-classification\n",
    "    conf_misclassification = 1- conf_accuracy\n",
    "\n",
    "    # Calcular Sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "    # Calcular Specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "\n",
    "    # Calcular la Precisión\n",
    "    conf_precision = (TP / float(TP + FP))\n",
    "    # Calcular f_1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "\n",
    "    precision = conf_precision\n",
    "    sensitivity = conf_sensitivity\n",
    "    specificity = conf_specificity\n",
    "\n",
    "    return precision, sensitivity, specificity, conf_f1, conf_misclassification\n",
    "\n",
    "def create_model(input_shape, n_outputs): # Convolutional Neural Network\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv1D(filters=100, kernel_size=4, activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv1D(filters=100, kernel_size=5, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def change_index(df):\n",
    "    #Cambiar indices de filas y columnas por valores numéricos\n",
    "    total_rows_df = df.shape[0]\n",
    "    df.index = np.arange(0, total_rows_df)\n",
    "\n",
    "    total_columns_df = df.shape[1]\n",
    "    df.columns = np.arange(0, total_columns_df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset de Entrenamiento (80% de los datos originales): Creación del Modelo y Obtención de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACP(alphabeth, db_selection): \n",
    "    \n",
    "    # Leer Datasets ========================================================\n",
    "    path_alphabet_nf = 'Databases/NoFeature/nf_DipoleMoment.txt'\n",
    "    path_alphabet_full = 'Databases/Full/full_DipoleMoment.txt'\n",
    "\n",
    "    df_nf = pd.read_csv(path_alphabet_nf, sep=\" \", header=None)\n",
    "    #ind_nf = pd.read_csv(path_independent_nf, sep=\" \", header=None)\n",
    "\n",
    "    df_full = pd.read_csv(path_alphabet_full, sep=\" \", header=None)\n",
    "    #ind_full = pd.read_csv(path_independent_full, sep=\" \", header=None)\n",
    "    #=======================================================================\n",
    "    \n",
    "    #Seleccionar entre los dos Datasets\n",
    "    if (db_selection == 0):\n",
    "        df_model = df_nf\n",
    "        db = 'NoFeature'\n",
    "        #df_ind = ind_nf\n",
    "    elif (db_selection == 1):\n",
    "        df_model = df_full\n",
    "        db = 'Full'\n",
    "        #df_ind = ind_full\n",
    "\n",
    "    #frames = [df_model_temp, df_ind]\n",
    "    #df_model = pd.concat(frames)\n",
    "\n",
    "    df_model = change_index(df_model)\n",
    "\n",
    "    X, y = build_datasets(df_model)\n",
    "    \n",
    "    # =============================================================================================\n",
    "    # Construcción de los Datasets de Entrenamiento (90%) y Testing (10%) =========================\n",
    "    \n",
    "    # Una vez se tiene el Dataset de Entrenamiento (80% de los datos originales) y el Dataset Independiente (20% de los datos originales), ...\n",
    "    # ... se debe utilizar el Dataset de Entrenamiento para obtener los Datasets de Training (90% del Dataset de Entrenamiento) ...\n",
    "    # ... y Testing (10% del Dataset de Entrenamiento). De esta forma se entrena y prueba el modelo, para luego validarlo con ...\n",
    "    # ... el Dataset Independiente. \n",
    "    \n",
    "    # 90% Training - 10% Testing\n",
    "    X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    y_main = y_main.to_numpy()\n",
    "    \n",
    "    # =============================================================================================\n",
    "\n",
    "    # Model ---------------------------------------------------------------------------------------\n",
    "    epochs = 50\n",
    "    batch_size = 50\n",
    "    verbose = 0\n",
    "    count = 1\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    kf.get_n_splits(X_main)\n",
    "    \n",
    "    # Diccionarios que almacenan los resultados de las métricas ====================================\n",
    "    dict_metrics = {alphabeth : {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], \n",
    "                                'precision':[], 'sensitivity':[], 'specificity':[], 'f1':[], 'auc':[], \n",
    "                                'mcc':[], 'mse':[], 'misc':[]}}\n",
    "\n",
    "    dict_metrics_test = {alphabeth : {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], \n",
    "                                'precision':[], 'sensitivity':[], 'specificity':[], 'f1':[], 'auc':[], \n",
    "                                'mcc':[], 'mse':[], 'misc':[]}}\n",
    "\n",
    "    # Entrenamiento del modelo con 5 Fold Cross Validation =======================================\n",
    "    for train_index, test_index in kf.split(X_main):\n",
    "        \n",
    "        # Entrenamiento - Validación\n",
    "        X_train, X_test = X_main[train_index], X_main[test_index]\n",
    "        y_train, y_test = y_main[train_index], y_main[test_index]\n",
    "\n",
    "        # CNN ====================================================================================\n",
    "        \n",
    "        # Configuración de los datos\n",
    "        X_train = np.expand_dims(X_train, axis=2)\n",
    "        X_test = np.expand_dims(X_test, axis=2)\n",
    "        y_train = to_categorical(y_train, 2)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "\n",
    "        n_timesteps, n_features, n_outputs = X_train.shape[0], X_train.shape[1], y_train.shape[1]\n",
    "        input_shape = (n_features,1)\n",
    "        \n",
    "        # Creación del Modelo (CNN) =============================================================\n",
    "        model = create_model(input_shape, n_outputs)\n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "\n",
    "        # Guardar cada uno de los Modelos creados ===============================================\n",
    "        filename = 'SavedModel/FinalModel/'+db+'/'+alphabeth+'_'+str(count)+'.h5'\n",
    "        model.save(filename)\n",
    "        \n",
    "        # Obtener Métricas ======================================================================\n",
    "        (_, acc_train) = model.evaluate(X_train, y_train, verbose=0)\n",
    "        (_, acc_test) = model.evaluate(X_test, y_test, verbose=0)\n",
    "        dict_metrics[alphabeth][\"accuracy_train\"].append(acc_train)\n",
    "        dict_metrics[alphabeth][\"accuracy_test\"].append(acc_test)\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = model.predict(X_test, batch_size=batch_size, verbose=0)\n",
    "        y_pred = np.argmax(new_predictions, axis=1)\n",
    "        y_t = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        # MSE\n",
    "        dict_metrics[alphabeth][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics[alphabeth][\"precision\"].append(precision)\n",
    "        dict_metrics[alphabeth][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics[alphabeth][\"specificity\"].append(specificity)\n",
    "        dict_metrics[alphabeth][\"f1\"].append(conf_f1)\n",
    "        dict_metrics[alphabeth][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics[alphabeth][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics[alphabeth][\"mcc\"].append(mcc_score)\n",
    "        \n",
    "        count = count + 1\n",
    "    #================================================================================================================\n",
    "    # Testing\n",
    "    # Con los modelos ya guardados se prueba cada uno de los modelos con datos desconocidos que están almacenados ...\n",
    "    # ... en el Dataset de Testing (10% del Dataset de Entrenamiento)\n",
    "\n",
    "    X_testing = np.expand_dims(X_testing, axis=2)\n",
    "    y_testing = to_categorical(y_testing, 2)\n",
    "\n",
    "    for count in range (5): # Cargar cada uno de los 5 \"modelos\" guardados en cada \"Fold\" mediante 5F-CV\n",
    "        # Cargar Modelo =============================================================================================\n",
    "        filename = 'SavedModel/FinalModel/'+db+'/'+alphabeth+'_'+str(count+1)+'.h5'\n",
    "        new_model = keras.models.load_model(filename)\n",
    "        \n",
    "        # Testing Accuracy\n",
    "        (_, acc_test) = new_model.evaluate(X_testing, y_testing, verbose=0)\n",
    "        dict_metrics_test[alphabeth][\"accuracy_train\"].append(0)\n",
    "        dict_metrics_test[alphabeth][\"accuracy_test\"].append(acc_test)\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = new_model.predict(X_testing)\n",
    "        y_pred = np.argmax(new_predictions, axis=1)\n",
    "        y_t = np.argmax(y_testing, axis=1)\n",
    "\n",
    "        # MSE\n",
    "        dict_metrics_test[alphabeth][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics_test[alphabeth][\"precision\"].append(precision)\n",
    "        dict_metrics_test[alphabeth][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics_test[alphabeth][\"specificity\"].append(specificity)\n",
    "        dict_metrics_test[alphabeth][\"f1\"].append(conf_f1)\n",
    "        dict_metrics_test[alphabeth][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics_test[alphabeth][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics_test[alphabeth][\"mcc\"].append(mcc_score)\n",
    "\n",
    "    return dict_metrics, dict_metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener Métricas de Entrenamiento y Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database:  No Feature   dipolemoment  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  100.0\n",
      "Accuracy Testing:  99.48717951774597\n",
      "Precision:  99.71325796505653\n",
      "Sensitivity:  99.2660850599782\n",
      "Specificity:  99.69924812030075\n",
      "f_1 Score:  99.48824293985584\n",
      "MCC:  98.97595990926243\n",
      "AUC Score:  99.48266659013947\n",
      "MSE:  0.005128205128205128\n",
      "Mis-Classification:  0.00512820512820511\n",
      "                                      1      2                    3  \\\n",
      "Accuracy Training   100.000000000000000  100.0  100.000000000000000   \n",
      "Accuracy Test        99.267399311065674  100.0   99.267399311065674   \n",
      "Precision            99.285714285714292  100.0  100.000000000000000   \n",
      "Sensitivity          99.285714285714292  100.0   98.473282442748086   \n",
      "Specificity          99.248120300751879  100.0  100.000000000000000   \n",
      "f_1 Score            99.285714285714292  100.0   99.230769230769226   \n",
      "MCC                  98.533834586466156  100.0   98.542172679709367   \n",
      "AUC Score            99.266917293233078  100.0   99.236641221374043   \n",
      "MSE                   0.007326007326007    0.0    0.007326007326007   \n",
      "Mis-Classification    0.007326007326007    0.0    0.007326007326007   \n",
      "\n",
      "                                      4      5  \n",
      "Accuracy Training   100.000000000000000  100.0  \n",
      "Accuracy Test        98.901098966598511  100.0  \n",
      "Precision            99.280575539568346  100.0  \n",
      "Sensitivity          98.571428571428584  100.0  \n",
      "Specificity          99.248120300751879  100.0  \n",
      "f_1 Score            98.924731182795696  100.0  \n",
      "MCC                  97.803792280136619  100.0  \n",
      "AUC Score            98.909774436090217  100.0  \n",
      "MSE                   0.010989010989011    0.0  \n",
      "Mis-Classification    0.010989010989011    0.0  \n",
      "Database:  No Feature   dipolemoment  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  99.86842155456543\n",
      "Precision:  100.0\n",
      "Sensitivity:  99.73684210526315\n",
      "Specificity:  100.0\n",
      "f_1 Score:  99.86754966887416\n",
      "MCC:  99.73855084879307\n",
      "AUC Score:  99.86842105263159\n",
      "MSE:  0.0013157894736842105\n",
      "Mis-Classification:  0.0013157894736842036\n",
      "                        1      2      3      4                    5\n",
      "Accuracy Training     0.0    0.0    0.0    0.0    0.000000000000000\n",
      "Accuracy Test       100.0  100.0  100.0  100.0   99.342107772827148\n",
      "Precision           100.0  100.0  100.0  100.0  100.000000000000000\n",
      "Sensitivity         100.0  100.0  100.0  100.0   98.684210526315780\n",
      "Specificity         100.0  100.0  100.0  100.0  100.000000000000000\n",
      "f_1 Score           100.0  100.0  100.0  100.0   99.337748344370851\n",
      "MCC                 100.0  100.0  100.0  100.0   98.692754243965354\n",
      "AUC Score           100.0  100.0  100.0  100.0   99.342105263157904\n",
      "MSE                   0.0    0.0    0.0    0.0    0.006578947368421\n",
      "Mis-Classification    0.0    0.0    0.0    0.0    0.006578947368421\n",
      "Database:  Full   dipolemoment  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  100.0\n",
      "Accuracy Testing:  99.34012055397034\n",
      "Precision:  100.0\n",
      "Sensitivity:  98.69465648854961\n",
      "Specificity:  100.0\n",
      "f_1 Score:  99.34177756378624\n",
      "MCC:  98.69044165776735\n",
      "AUC Score:  99.34732824427482\n",
      "MSE:  0.006598793363499246\n",
      "Mis-Classification:  0.006598793363499222\n",
      "                                      1      2                    3  \\\n",
      "Accuracy Training   100.000000000000000  100.0  100.000000000000000   \n",
      "Accuracy Test        99.267399311065674  100.0   99.267399311065674   \n",
      "Precision           100.000000000000000  100.0  100.000000000000000   \n",
      "Sensitivity          98.571428571428584  100.0   98.473282442748086   \n",
      "Specificity         100.000000000000000  100.0  100.000000000000000   \n",
      "f_1 Score            99.280575539568346  100.0   99.230769230769226   \n",
      "MCC                  98.544969993963221  100.0   98.542172679709367   \n",
      "AUC Score            99.285714285714292  100.0   99.236641221374043   \n",
      "MSE                   0.007326007326007    0.0    0.007326007326007   \n",
      "Mis-Classification    0.007326007326007    0.0    0.007326007326007   \n",
      "\n",
      "                                      4                    5  \n",
      "Accuracy Training   100.000000000000000  100.000000000000000  \n",
      "Accuracy Test        98.901098966598511   99.264705181121826  \n",
      "Precision           100.000000000000000  100.000000000000000  \n",
      "Sensitivity          97.857142857142847   98.571428571428584  \n",
      "Specificity         100.000000000000000  100.000000000000000  \n",
      "f_1 Score            98.916967509025270   99.280575539568346  \n",
      "MCC                  97.825625176517377   98.539440438646793  \n",
      "AUC Score            98.928571428571431   99.285714285714292  \n",
      "MSE                   0.010989010989011    0.007352941176471  \n",
      "Mis-Classification    0.010989010989011    0.007352941176471  \n",
      "Database:  Full   dipolemoment  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  100.0\n",
      "Precision:  100.0\n",
      "Sensitivity:  100.0\n",
      "Specificity:  100.0\n",
      "f_1 Score:  100.0\n",
      "MCC:  100.0\n",
      "AUC Score:  100.0\n",
      "MSE:  0.0\n",
      "Mis-Classification:  0.0\n",
      "                        1      2      3      4      5\n",
      "Accuracy Training     0.0    0.0    0.0    0.0    0.0\n",
      "Accuracy Test       100.0  100.0  100.0  100.0  100.0\n",
      "Precision           100.0  100.0  100.0  100.0  100.0\n",
      "Sensitivity         100.0  100.0  100.0  100.0  100.0\n",
      "Specificity         100.0  100.0  100.0  100.0  100.0\n",
      "f_1 Score           100.0  100.0  100.0  100.0  100.0\n",
      "MCC                 100.0  100.0  100.0  100.0  100.0\n",
      "AUC Score           100.0  100.0  100.0  100.0  100.0\n",
      "MSE                   0.0    0.0    0.0    0.0    0.0\n",
      "Mis-Classification    0.0    0.0    0.0    0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "alphabeth = 'dipolemoment'\n",
    "db = [0,1]\n",
    "\n",
    "for db_selection in db:\n",
    "    dict_metrics, dict_metrics_test = ACP(alphabeth, db_selection)\n",
    "\n",
    "    print_metrics(dict_metrics[alphabeth], alphabeth, db_selection, folder='Training')\n",
    "    print_metrics(dict_metrics_test[alphabeth], alphabeth, db_selection, folder='Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Independiente (20% de los datos Originales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def independent(alphabeth, db_selection):\n",
    "\n",
    "    path_alphabet_nf = 'Databases/NoFeature/ind_nf_dipoleMoment.txt'\n",
    "    path_alphabet_full = 'Databases/Full/ind_full_dipolemoment.txt'\n",
    "\n",
    "    ind_nf = pd.read_csv(path_alphabet_nf, sep=\" \", header=None)\n",
    "    ind_full = pd.read_csv(path_alphabet_full, sep=\" \", header=None)\n",
    "\n",
    "    if (db_selection == 0):\n",
    "        df_model = ind_nf\n",
    "        db = 'NoFeature'\n",
    "    elif (db_selection == 1):\n",
    "        df_model = ind_full\n",
    "        db = 'Full'\n",
    "        \n",
    "    df_model = change_index(df_model)\n",
    "\n",
    "    X_ind, y_ind = build_datasets(df_model)\n",
    "        \n",
    "    dict_metrics_ind = {alphabeth : {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], \n",
    "                                'precision':[], 'sensitivity':[], 'specificity':[], 'f1':[], 'auc':[], \n",
    "                                'mcc':[], 'mse':[], 'misc':[]}}\n",
    "    \n",
    "    batch_size = 50\n",
    "    count = 1\n",
    "    \n",
    "    X_ind = np.expand_dims(X_ind, axis=2)\n",
    "    y_ind = to_categorical(y_ind, 2)\n",
    "    \n",
    "    for count in range (5):\n",
    "        filename = 'SavedModel/FinalModel/'+db+'/'+alphabeth+'_'+str(count+1)+'.h5'\n",
    "        new_model = keras.models.load_model(filename)\n",
    "        \n",
    "        # Testing Accuracy\n",
    "        (_, acc_test) = new_model.evaluate(X_ind, y_ind, verbose=0)\n",
    "        dict_metrics_ind[alphabeth][\"accuracy_train\"].append(0)\n",
    "        dict_metrics_ind[alphabeth][\"accuracy_test\"].append(acc_test)\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = new_model.predict(X_ind)\n",
    "        y_pred = np.argmax(new_predictions, axis=1)\n",
    "        y_t = np.argmax(y_ind, axis=1)\n",
    "\n",
    "        # MSE\n",
    "        dict_metrics_ind[alphabeth][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics_ind[alphabeth][\"precision\"].append(precision)\n",
    "        dict_metrics_ind[alphabeth][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics_ind[alphabeth][\"specificity\"].append(specificity)\n",
    "        dict_metrics_ind[alphabeth][\"f1\"].append(conf_f1)\n",
    "        dict_metrics_ind[alphabeth][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics_ind[alphabeth][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics_ind[alphabeth][\"mcc\"].append(mcc_score)\n",
    "\n",
    "    return dict_metrics_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database:  No Feature   dipolemoment  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  96.99999928474426\n",
      "Precision:  95.0623450497375\n",
      "Sensitivity:  99.1578947368421\n",
      "Specificity:  94.84210526315789\n",
      "f_1 Score:  97.06511660558593\n",
      "MCC:  94.09122633457706\n",
      "AUC Score:  97.0\n",
      "MSE:  0.03\n",
      "Mis-Classification:  0.02999999999999998\n",
      "                                     1                   2  \\\n",
      "Accuracy Training    0.000000000000000   0.000000000000000   \n",
      "Accuracy Test       96.052628755569458  97.894734144210815   \n",
      "Precision           93.969849246231149  96.428571428571431   \n",
      "Sensitivity         98.421052631578945  99.473684210526315   \n",
      "Specificity         93.684210526315795  96.315789473684205   \n",
      "f_1 Score           96.143958868894600  97.927461139896394   \n",
      "MCC                 92.208768761783361  95.837271500683130   \n",
      "AUC Score           96.052631578947370  97.894736842105260   \n",
      "MSE                  0.039473684210526   0.021052631578947   \n",
      "Mis-Classification   0.039473684210526   0.021052631578947   \n",
      "\n",
      "                                     3                   4  \\\n",
      "Accuracy Training    0.000000000000000   0.000000000000000   \n",
      "Accuracy Test       96.578949689865112  96.578949689865112   \n",
      "Precision           94.029850746268664  94.923857868020306   \n",
      "Sensitivity         99.473684210526315  98.421052631578945   \n",
      "Specificity         93.684210526315795  94.736842105263150   \n",
      "f_1 Score           96.675191815856792  96.640826873385009   \n",
      "MCC                 93.314411648625367  93.221182673572997   \n",
      "AUC Score           96.578947368421055  96.578947368421055   \n",
      "MSE                  0.034210526315789   0.034210526315789   \n",
      "Mis-Classification   0.034210526315789   0.034210526315789   \n",
      "\n",
      "                                      5  \n",
      "Accuracy Training     0.000000000000000  \n",
      "Accuracy Test        97.894734144210815  \n",
      "Precision            95.959595959595958  \n",
      "Sensitivity         100.000000000000000  \n",
      "Specificity          95.789473684210520  \n",
      "f_1 Score            97.938144329896900  \n",
      "MCC                  95.874497088220451  \n",
      "AUC Score            97.894736842105260  \n",
      "MSE                   0.021052631578947  \n",
      "Mis-Classification    0.021052631578947  \n",
      "Database:  Full   dipolemoment  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  98.68421077728271\n",
      "Precision:  98.13134313330649\n",
      "Sensitivity:  99.26315789473684\n",
      "Specificity:  98.10526315789474\n",
      "f_1 Score:  98.69258108562227\n",
      "MCC:  97.37780362872013\n",
      "AUC Score:  98.68421052631578\n",
      "MSE:  0.013157894736842105\n",
      "Mis-Classification:  0.013157894736842101\n",
      "                                     1                   2  \\\n",
      "Accuracy Training    0.000000000000000   0.000000000000000   \n",
      "Accuracy Test       98.947370052337646  99.210524559020996   \n",
      "Precision           98.437500000000000  98.952879581151834   \n",
      "Sensitivity         99.473684210526315  99.473684210526315   \n",
      "Specificity         98.421052631578945  98.947368421052630   \n",
      "f_1 Score           98.952879581151834  99.212598425196859   \n",
      "MCC                 97.900160823982816  98.422415832374483   \n",
      "AUC Score           98.947368421052630  99.210526315789465   \n",
      "MSE                  0.010526315789474   0.007894736842105   \n",
      "Mis-Classification   0.010526315789474   0.007894736842105   \n",
      "\n",
      "                                     3                   4                   5  \n",
      "Accuracy Training    0.000000000000000   0.000000000000000   0.000000000000000  \n",
      "Accuracy Test       98.157894611358643  98.947370052337646  98.157894611358643  \n",
      "Precision           97.905759162303667  98.437500000000000  96.923076923076920  \n",
      "Sensitivity         98.421052631578945  99.473684210526315  99.473684210526315  \n",
      "Specificity         97.894736842105274  98.421052631578945  96.842105263157890  \n",
      "f_1 Score           98.162729658792642  98.952879581151834  98.181818181818187  \n",
      "MCC                 96.317123515104427  97.900160823982816  96.349157148156124  \n",
      "AUC Score           98.157894736842110  98.947368421052630  98.157894736842096  \n",
      "MSE                  0.018421052631579   0.010526315789474   0.018421052631579  \n",
      "Mis-Classification   0.018421052631579   0.010526315789474   0.018421052631579  \n"
     ]
    }
   ],
   "source": [
    "alphabeth = 'dipolemoment'\n",
    "db = [0,1]\n",
    "\n",
    "for db_selection in db:\n",
    "    dict_metrics_ind = independent(alphabeth, db_selection)\n",
    "\n",
    "    print_metrics(dict_metrics_ind[alphabeth], alphabeth, db_selection, folder='Independent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
