{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from numpy import linalg #SVD\n",
    "import screed \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statistics\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "random_seed = 600\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "#---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics, db_choosen, model_name):\n",
    "    print('-'*50)\n",
    "    db = \"No Feature\" if db_choosen == 0 else \"Full\"\n",
    "    print(\"Database: \", db,\" \", model_name,\" \\n\")\n",
    "    print('-'*50)\n",
    "    if (db_choosen == 0):\n",
    "        print('Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder')\n",
    "    elif (db_choosen == 1):\n",
    "        print('Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)')\n",
    "    print('-'*50)\n",
    "    print('Accuracy Training: ', statistics.mean(metrics[\"accuracy_train\"])*100)\n",
    "    print('Accuracy Testing: ', statistics.mean(metrics[\"accuracy_test\"])*100)\n",
    "    print('Precision: ', statistics.mean(metrics[\"precision\"])*100)\n",
    "    print('Sensitivity: ', statistics.mean(metrics[\"sensitivity\"])*100) \n",
    "    print('Specificity: ', statistics.mean(metrics[\"specificity\"])*100)\n",
    "    print('f_1 Score: ', statistics.mean(metrics[\"f1\"])*100)\n",
    "    print('MCC: ', statistics.mean(metrics[\"mcc\"])*100) \n",
    "    print('AUC Score: ', statistics.mean(metrics[\"auc\"])*100) \n",
    "    print('MSE: ', statistics.mean(metrics[\"mse\"]))\n",
    "    print('Mis-Classification: ', statistics.mean(metrics[\"misc\"])) \n",
    "\n",
    "    #Mostrar más decimales en DF\n",
    "    pd.set_option(\"display.precision\", 15)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    metrics_model = [metrics[\"accuracy_train\"], metrics[\"accuracy_test\"], metrics[\"precision\"], metrics[\"sensitivity\"], metrics[\"specificity\"], metrics[\"mcc\"], metrics[\"auc\"], metrics[\"f1\"], metrics[\"misc\"]]\n",
    "    metrics_m = pd.DataFrame(metrics_model, columns = ['1', '2','3', '4', '5'],index = ['Accuracy Training','Accuracy Test', 'Precision', 'Sensitivity', 'Specificity', 'MCC', 'AUC Score', 'f_1 Score','Mis-Classification'])\n",
    "    print(metrics_m)\n",
    "\n",
    "def confusion_metrics(conf_matrix):\n",
    "    # Guardar la matriz de confusión y dividirla en 4 piezas\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "\n",
    "    # Calcular Precisión\n",
    "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "\n",
    "    # Calcular mis-classification\n",
    "    conf_misclassification = 1- conf_accuracy\n",
    "\n",
    "    # Calcular Sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "    # Calcular Specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "\n",
    "    # Calcular la Precisión\n",
    "    conf_precision = (TP / float(TP + FP))\n",
    "    # Calcular f_1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "\n",
    "    precision = conf_precision\n",
    "    sensitivity = conf_sensitivity\n",
    "    specificity = conf_specificity\n",
    "\n",
    "    return precision, sensitivity, specificity, conf_f1, conf_misclassification\n",
    "\n",
    "def create_model_lstm(input_shape, n_outputs):\n",
    "    #opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_cnn(input_shape, n_outputs):\n",
    "    opt = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, activation='softsign', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='softsign'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def change_index(df):\n",
    "    #Cambiar indices de filas y columnas por valores numéricos\n",
    "    total_rows_df = df.shape[0]\n",
    "    df.index = np.arange(0, total_rows_df)\n",
    "\n",
    "    total_columns_df = df.shape[1]\n",
    "    df.columns = np.arange(0, total_columns_df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_datasets(df_model):\n",
    "    X = df_model.iloc[:, :-1]\n",
    "\n",
    "    y = df_model.iloc[:,-1]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(db_choosen, db):\n",
    "\n",
    "    path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "    path_full = 'Databases/Full/full_polarizability.txt'\n",
    "    \n",
    "    df_nf= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "    df_full = pd.read_csv(path_full, sep=\" \", header=None)\n",
    "\n",
    "    if(db_choosen == 0):\n",
    "        df_model = df_nf\n",
    "        path_choosen = path_nf\n",
    "    elif(db_choosen == 1):\n",
    "        df_model = df_full\n",
    "        path_choosen = path_full\n",
    "\n",
    "    df_model = change_index(df_model)\n",
    "\n",
    "    X, y = build_datasets(df_model)\n",
    "\n",
    "    #Counter(y).keys() # equals to list(set(words))\n",
    "    #Counter(y).values() # counts the elements' frequency\n",
    "    print(\"\\n\")\n",
    "    print(\"_\"*70)\n",
    "    print(\"_\"*70)\n",
    "    print(\"\\n\")\n",
    "    #print(\"Dataset Shape: X = %s, Y = %s\" %(X.shape, y.shape))\n",
    "    #print(\"Positives Samples = %i, Negatives Samples = %i\" %(list(Counter(y).values())[0] , list(Counter(y).values())[1]))\n",
    "    \n",
    "    X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    y_main = y_main.to_numpy()\n",
    "    \n",
    "    #print(\"\\nDataset Train Shape (90): X = %s, Y = %s\" %(X_main.shape, y_main.shape))\n",
    "    #print(\"Dataset Test Shape (10): X = %s, Y = %s\" %(X_testing.shape, y_testing.shape))\n",
    "    #print(\"\\nPositives Samples Train = %i, Negatives Samples = %i\" %(list(Counter(y_main).values())[0] , list(Counter(y_main).values())[1]))\n",
    "    #print(y.shape)\n",
    "    #print(\"Positives Samples Test = %i, Negatives Samples = %i\" %(list(Counter(y_testing).values())[0] , list(Counter(y_testing).values())[1]))\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    kf.get_n_splits(X_main)\n",
    "\n",
    "    batch_size = 32\n",
    "    epoch = 10\n",
    "    verbose = 0\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    dict_metrics = { \"RF\" : {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                             'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                      \"SVM\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                              'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                      \"LSTM\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                               'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                      \"CNN\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                              'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},                \n",
    "                    }\n",
    "\n",
    "    for train_index, test_index in kf.split(X_main):\n",
    "\n",
    "        X_train, X_test = X_main[train_index], X_main[test_index]\n",
    "        y_train, y_test = y_main[train_index], y_main[test_index]\n",
    "\n",
    "        #______________________________________________________________________________________________________\n",
    "        #RF---------------------------------------------------------------------------------------------------\n",
    "        #model_rf = RandomForestClassifier(max_depth=1, random_state = 42)\n",
    "        model_rf = RandomForestClassifier(max_depth=2, max_features=2, random_state = 42)\n",
    "        model_rf.fit(X_train, y_train)\n",
    "        \n",
    "        filename = 'SavedModel/'+db+'/rf_'+str(count)+'.sav'\n",
    "        pickle.dump(model_rf, open(filename, 'wb'))\n",
    "\n",
    "        # Testing Accuracy\n",
    "        dict_metrics[\"RF\"][\"accuracy_train\"].append(model_rf.score(X_train, y_train))\n",
    "        dict_metrics[\"RF\"][\"accuracy_test\"].append(model_rf.score(X_test, y_test))\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = model_rf.predict(X_test)\n",
    "        y_pred = new_predictions\n",
    "        y_t = y_test\n",
    "        \n",
    "        # MSE\n",
    "        dict_metrics[\"RF\"][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics[\"RF\"][\"precision\"].append(precision)\n",
    "        dict_metrics[\"RF\"][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics[\"RF\"][\"specificity\"].append(specificity)\n",
    "        dict_metrics[\"RF\"][\"f1\"].append(conf_f1)\n",
    "        dict_metrics[\"RF\"][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics[\"RF\"][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics[\"RF\"][\"mcc\"].append(mcc_score)\n",
    "    \n",
    "        #______________________________________________________________________________________________________\n",
    "        #SVM---------------------------------------------------------------------------------------------------\n",
    "        #model_svm = svm.SVC(kernel='linear', verbose = False) # Linear Kernel\n",
    "        model_svm = svm.SVC(kernel='rbf', gamma='auto', C=1, verbose = False) # Linear Kernel\n",
    "        model_svm.fit(X_train, y_train)\n",
    "        \n",
    "        filename = 'SavedModel/'+db+'/svm_'+str(count)+'.sav'\n",
    "        pickle.dump(model_svm, open(filename, 'wb'))\n",
    "\n",
    "        # Testing Accuracy\n",
    "        dict_metrics[\"SVM\"][\"accuracy_train\"].append(model_svm.score(X_train, y_train))\n",
    "        dict_metrics[\"SVM\"][\"accuracy_test\"].append(model_svm.score(X_test, y_test))\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = model_svm.predict(X_test)\n",
    "        y_pred = new_predictions\n",
    "        y_t = y_test\n",
    "        \n",
    "        # MSE\n",
    "        dict_metrics[\"SVM\"][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics[\"SVM\"][\"precision\"].append(precision)\n",
    "        dict_metrics[\"SVM\"][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics[\"SVM\"][\"specificity\"].append(specificity)\n",
    "        dict_metrics[\"SVM\"][\"f1\"].append(conf_f1)\n",
    "        dict_metrics[\"SVM\"][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics[\"SVM\"][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics[\"SVM\"][\"mcc\"].append(mcc_score)\n",
    "\n",
    "        #______________________________________________________________________________________________________\n",
    "        #LSTM--------------------------------------------------------------------------------------------------\n",
    "        X_train_lstm = np.expand_dims(X_train, axis=2)\n",
    "        X_test_lstm = np.expand_dims(X_test, axis=2)\n",
    "        y_train_lstm = to_categorical(y_train, 2)\n",
    "        y_test_lstm = to_categorical(y_test, 2)\n",
    "\n",
    "        n_timesteps, n_features, n_outputs = X_train_lstm.shape[0], X_train_lstm.shape[1], y_train_lstm.shape[1]\n",
    "        input_shape = (n_features,1)\n",
    "\n",
    "        model_lstm = create_model_lstm(input_shape, n_outputs)\n",
    "        model_lstm.fit(X_train_lstm,y_train_lstm,verbose=0)\n",
    "        \n",
    "        model_lstm.save('SavedModel/'+db+'/lstm_'+str(count)+'.h5')\n",
    "\n",
    "        (_, lstm_acc_train) = model_lstm.evaluate(X_train_lstm, y_train_lstm, verbose=0)\n",
    "        (_, lstm_acc_test) = model_lstm.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "        dict_metrics[\"LSTM\"][\"accuracy_train\"].append(lstm_acc_train)\n",
    "        dict_metrics[\"LSTM\"][\"accuracy_test\"].append(lstm_acc_test)\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = model_lstm.predict(X_test_lstm, batch_size=batch_size, verbose=0)\n",
    "        y_pred = np.argmax(new_predictions, axis=1)\n",
    "        y_t = np.argmax(y_test_lstm, axis=1)\n",
    "        \n",
    "        # MSE\n",
    "        dict_metrics[\"LSTM\"][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics[\"LSTM\"][\"precision\"].append(precision)\n",
    "        dict_metrics[\"LSTM\"][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics[\"LSTM\"][\"specificity\"].append(specificity)\n",
    "        dict_metrics[\"LSTM\"][\"f1\"].append(conf_f1)\n",
    "        dict_metrics[\"LSTM\"][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics[\"LSTM\"][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics[\"LSTM\"][\"mcc\"].append(mcc_score)\n",
    "\n",
    "        #______________________________________________________________________________________________________\n",
    "        #CNN---------------------------------------------------------------------------------------------------\n",
    "        X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "        X_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "        y_train_cnn = to_categorical(y_train, 2)\n",
    "        y_test_cnn = to_categorical(y_test, 2)\n",
    "\n",
    "        n_timesteps, n_features, n_outputs = X_train_cnn.shape[0], X_train_cnn.shape[1], y_train_cnn.shape[1]\n",
    "        input_shape = (n_features,1)\n",
    "\n",
    "        model_cnn = create_model_cnn(input_shape, n_outputs)\n",
    "        model_cnn.fit(X_train_cnn,y_train_cnn,batch_size=150,verbose=0)\n",
    "        \n",
    "        model_cnn.save('SavedModel/'+db+'/cnn_'+str(count)+'.h5')\n",
    "\n",
    "        (_, cnn_acc_train) = model_cnn.evaluate(X_train_cnn, y_train_cnn, verbose=0)\n",
    "        (_, cnn_acc_test) = model_cnn.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "        dict_metrics[\"CNN\"][\"accuracy_train\"].append(cnn_acc_train)\n",
    "        dict_metrics[\"CNN\"][\"accuracy_test\"].append(cnn_acc_test)\n",
    "\n",
    "        # Predicciones\n",
    "        new_predictions = model_cnn.predict(X_test_cnn, batch_size=batch_size, verbose=0)\n",
    "        y_pred = np.argmax(new_predictions, axis=1)\n",
    "        y_t = np.argmax(y_test_cnn, axis=1)\n",
    "        \n",
    "        # MSE\n",
    "        dict_metrics[\"CNN\"][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "        # Cálculo de métricas\n",
    "        cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "        precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "        dict_metrics[\"CNN\"][\"precision\"].append(precision)\n",
    "        dict_metrics[\"CNN\"][\"sensitivity\"].append(sensitivity)\n",
    "        dict_metrics[\"CNN\"][\"specificity\"].append(specificity)\n",
    "        dict_metrics[\"CNN\"][\"f1\"].append(conf_f1)\n",
    "        dict_metrics[\"CNN\"][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "        #ROC and AUC Score\n",
    "        auc_score = roc_auc_score(y_t, y_pred)\n",
    "        dict_metrics[\"CNN\"][\"auc\"].append(auc_score)\n",
    "\n",
    "        #MCC\n",
    "        mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "        dict_metrics[\"CNN\"][\"mcc\"].append(mcc_score)\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "    return dict_metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "______________________________________________________________________\n",
      "______________________________________________________________________\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Database:  No Feature   Random Forest  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  97.8556655687728\n",
      "Accuracy Testing:  96.4802844214609\n",
      "Precision:  97.64833145774868\n",
      "Sensitivity:  95.38931297709924\n",
      "Specificity:  97.71674705329264\n",
      "f_1 Score:  96.43778423988009\n",
      "MCC:  93.11627434338439\n",
      "AUC Score:  96.55303001519594\n",
      "MSE:  0.03519715578539108\n",
      "Mis-Classification:  0.035197155785391065\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.979835013748854  0.975252062328139  0.976168652612282   \n",
      "Accuracy Test       0.956043956043956  0.978021978021978  0.959706959706960   \n",
      "Precision           1.000000000000000  0.969924812030075  0.934782608695652   \n",
      "Sensitivity         0.914285714285714  0.984732824427481  0.984732824427481   \n",
      "Specificity         1.000000000000000  0.971830985915493  0.936619718309859   \n",
      "MCC                 0.915762354355742  0.956101342249381  0.920659907961985   \n",
      "AUC Score           0.957142857142857  0.978281905171487  0.960676271368670   \n",
      "f_1 Score           0.955223880597015  0.977272727272727  0.959107806691450   \n",
      "Mis-Classification  0.043956043956044  0.021978021978022  0.040293040293040   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.988084326306141  0.973443223443223  \n",
      "Accuracy Test       0.974358974358974  0.955882352941177  \n",
      "Precision           0.985401459854015  0.992307692307692  \n",
      "Sensitivity         0.964285714285714  0.921428571428571  \n",
      "Specificity         0.984962406015038  0.992424242424242  \n",
      "MCC                 0.948942387901292  0.914347724700819  \n",
      "AUC Score           0.974624060150376  0.956926406926407  \n",
      "f_1 Score           0.974729241877256  0.955555555555556  \n",
      "Mis-Classification  0.025641025641026  0.044117647058823  \n",
      "--------------------------------------------------\n",
      "Database:  No Feature   Support Vector Machine  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  100.0\n",
      "Accuracy Testing:  96.84847015729369\n",
      "Precision:  99.37448130801324\n",
      "Sensitivity:  94.28135223555071\n",
      "Specificity:  99.41755797945568\n",
      "f_1 Score:  96.75711274412019\n",
      "MCC:  93.82084133307762\n",
      "AUC Score:  96.84945510750319\n",
      "MSE:  0.03151529842706313\n",
      "Mis-Classification:  0.03151529842706313\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   1.000000000000000  1.000000000000000  1.000000000000000   \n",
      "Accuracy Test       0.963369963369963  0.974358974358974  0.963369963369963   \n",
      "Precision           0.992424242424242  0.992063492063492  0.991869918699187   \n",
      "Sensitivity         0.935714285714286  0.954198473282443  0.931297709923664   \n",
      "Specificity         0.992481203007519  0.992957746478873  0.992957746478873   \n",
      "MCC                 0.928394950524627  0.949199488708664  0.928054878234640   \n",
      "AUC Score           0.964097744360902  0.973578109880658  0.962127728201269   \n",
      "f_1 Score           0.963235294117647  0.972762645914397  0.960629921259842   \n",
      "Mis-Classification  0.036630036630037  0.025641025641026  0.036630036630037   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   1.000000000000000  1.000000000000000  \n",
      "Accuracy Test       0.959706959706960  0.981617647058823  \n",
      "Precision           0.992366412213740  1.000000000000000  \n",
      "Sensitivity         0.928571428571429  0.964285714285714  \n",
      "Specificity         0.992481203007519  1.000000000000000  \n",
      "MCC                 0.921498146542480  0.963894602643470  \n",
      "AUC Score           0.960526315789474  0.982142857142857  \n",
      "f_1 Score           0.959409594095941  0.981818181818182  \n",
      "Mis-Classification  0.040293040293040  0.018382352941177  \n",
      "--------------------------------------------------\n",
      "Database:  No Feature   LSTM  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  95.6925630569458\n",
      "Accuracy Testing:  95.67630887031555\n",
      "Precision:  94.85994948319825\n",
      "Sensitivity:  96.61613958560523\n",
      "Specificity:  94.77252670729321\n",
      "f_1 Score:  95.6866015171461\n",
      "MCC:  91.44770045461279\n",
      "AUC Score:  95.69433314644922\n",
      "MSE:  0.043236910148674854\n",
      "Mis-Classification:  0.043236910148674854\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.971585690975189  0.950504124164581  0.942254841327667   \n",
      "Accuracy Test       0.963369965553284  0.956043958663940  0.934065937995911   \n",
      "Precision           0.992424242424242  0.928057553956835  0.924812030075188   \n",
      "Sensitivity         0.935714285714286  0.984732824427481  0.938931297709924   \n",
      "Specificity         0.992481203007519  0.929577464788732  0.929577464788732   \n",
      "MCC                 0.928394950524627  0.913721045144774  0.868088866212262   \n",
      "AUC Score           0.964097744360902  0.957155144608107  0.934254381249328   \n",
      "f_1 Score           0.963235294117647  0.955555555555555  0.931818181818182   \n",
      "Mis-Classification  0.036630036630037  0.043956043956044  0.065934065934066   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.949587523937225  0.970695972442627  \n",
      "Accuracy Test       0.948717951774597  0.981617629528046  \n",
      "Precision           0.925675675675676  0.972027972027972  \n",
      "Sensitivity         0.978571428571429  0.992857142857143  \n",
      "Specificity         0.917293233082707  0.969696969696970  \n",
      "MCC                 0.898765472251217  0.963414688597759  \n",
      "AUC Score           0.947932330827068  0.981277056277056  \n",
      "f_1 Score           0.951388888888889  0.982332155477032  \n",
      "Mis-Classification  0.051282051282051  0.018382352941177  \n",
      "--------------------------------------------------\n",
      "Database:  No Feature   CNN  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  98.95520567893982\n",
      "Accuracy Testing:  97.06825017929077\n",
      "Precision:  96.92582390521221\n",
      "Sensitivity:  97.19738276990185\n",
      "Specificity:  96.93399632243221\n",
      "f_1 Score:  97.05441057679305\n",
      "MCC:  94.14322382920987\n",
      "AUC Score:  97.06568954616704\n",
      "MSE:  0.029317496229260935\n",
      "Mis-Classification:  0.029317496229260942\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.994500458240509  0.986251175403595  0.984417974948883   \n",
      "Accuracy Test       0.978021979331970  0.963369965553284  0.967032968997955   \n",
      "Precision           0.978571428571429  0.948148148148148  0.976562500000000   \n",
      "Sensitivity         0.978571428571429  0.977099236641221  0.954198473282443   \n",
      "Specificity         0.977443609022556  0.950704225352113  0.978873239436620   \n",
      "MCC                 0.956015037593985  0.927105977683406  0.934126854596113   \n",
      "AUC Score           0.978007518796993  0.963901730996667  0.966535856359531   \n",
      "f_1 Score           0.978571428571429  0.962406015037594  0.965250965250965   \n",
      "Mis-Classification  0.021978021978022  0.036630036630037  0.032967032967033   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.989000916481018  0.993589758872986  \n",
      "Accuracy Test       0.963369965553284  0.981617629528046  \n",
      "Precision           0.964285714285714  0.978723404255319  \n",
      "Sensitivity         0.964285714285714  0.985714285714286  \n",
      "Specificity         0.962406015037594  0.977272727272727  \n",
      "MCC                 0.926691729323308  0.963221592263682  \n",
      "AUC Score           0.963345864661654  0.981493506493507  \n",
      "f_1 Score           0.964285714285714  0.982206405693950  \n",
      "Mis-Classification  0.036630036630037  0.018382352941177  \n"
     ]
    }
   ],
   "source": [
    "choosen=0 # 0: No Feature, 1: Full\n",
    "\n",
    "db = \"nf\" \n",
    "\n",
    "dict_metrics = model_selection(choosen, db)\n",
    "\n",
    "# RF-----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"RF\"], choosen, model_name = \"Random Forest\")\n",
    "\n",
    "# SVM----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"SVM\"], choosen, model_name = \"Support Vector Machine\")\n",
    "\n",
    "# LSTM---------------------------------------------------\n",
    "print_metrics(dict_metrics[\"LSTM\"], choosen, model_name = \"LSTM\")\n",
    "\n",
    "# CNN----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"CNN\"], choosen, model_name = \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "______________________________________________________________________\n",
      "______________________________________________________________________\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Database:  Full   Random Forest  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  92.9986435806784\n",
      "Accuracy Testing:  92.59534583063996\n",
      "Precision:  94.69032803021788\n",
      "Sensitivity:  90.3555070883315\n",
      "Specificity:  94.86841303001421\n",
      "f_1 Score:  92.42140149537691\n",
      "MCC:  85.35867401595758\n",
      "AUC Score:  92.61196005917286\n",
      "MSE:  0.07404654169360052\n",
      "Mis-Classification:  0.0740465416936005\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.933088909257562  0.930339138405133  0.928505957836847   \n",
      "Accuracy Test       0.904761904761905  0.941391941391941  0.923076923076923   \n",
      "Precision           0.959677419354839  0.967479674796748  0.916666666666667   \n",
      "Sensitivity         0.850000000000000  0.908396946564885  0.923664122137405   \n",
      "Specificity         0.962406015037594  0.971830985915493  0.922535211267606   \n",
      "MCC                 0.815565773781361  0.883846366324318  0.845971976584924   \n",
      "AUC Score           0.906203007518797  0.940113966240189  0.923099666702505   \n",
      "f_1 Score           0.901515151515152  0.937007874015748  0.920152091254753   \n",
      "Mis-Classification  0.095238095238095  0.058608058608059  0.076923076923077   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.934005499541705  0.923992673992674  \n",
      "Accuracy Test       0.934065934065934  0.926470588235294  \n",
      "Precision           0.962121212121212  0.928571428571429  \n",
      "Sensitivity         0.907142857142857  0.928571428571429  \n",
      "Specificity         0.962406015037594  0.924242424242424  \n",
      "MCC                 0.869735731293424  0.852813852813853  \n",
      "AUC Score           0.934774436090225  0.926406926406926  \n",
      "f_1 Score           0.933823529411765  0.928571428571429  \n",
      "Mis-Classification  0.065934065934066  0.073529411764706  \n",
      "--------------------------------------------------\n",
      "Database:  Full   Support Vector Machine  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  99.92668956463639\n",
      "Accuracy Testing:  96.84739280327516\n",
      "Precision:  99.2345841681161\n",
      "Sensitivity:  94.46346782988005\n",
      "Specificity:  99.264903616275\n",
      "f_1 Score:  96.7756190543582\n",
      "MCC:  93.8269757726963\n",
      "AUC Score:  96.86418572307753\n",
      "MSE:  0.03152607196724844\n",
      "Mis-Classification:  0.031526071967248416\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.999083409715857  1.000000000000000  0.999083409715857   \n",
      "Accuracy Test       0.959706959706960  0.989010989010989  0.963369963369963   \n",
      "Precision           0.992366412213740  0.992307692307692  0.991869918699187   \n",
      "Sensitivity         0.928571428571429  0.984732824427481  0.931297709923664   \n",
      "Specificity         0.992481203007519  0.992957746478873  0.992957746478873   \n",
      "MCC                 0.921498146542480  0.978006073707308  0.928054878234640   \n",
      "AUC Score           0.960526315789474  0.988845285453177  0.962127728201269   \n",
      "f_1 Score           0.959409594095941  0.988505747126437  0.960629921259842   \n",
      "Mis-Classification  0.040293040293040  0.010989010989011  0.036630036630037   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.999083409715857  0.999084249084249  \n",
      "Accuracy Test       0.963369963369963  0.966911764705882  \n",
      "Precision           1.000000000000000  0.985185185185185  \n",
      "Sensitivity         0.928571428571429  0.950000000000000  \n",
      "Specificity         1.000000000000000  0.984848484848485  \n",
      "MCC                 0.929320377284585  0.934469312865802  \n",
      "AUC Score           0.964285714285714  0.967424242424242  \n",
      "f_1 Score           0.962962962962963  0.967272727272727  \n",
      "Mis-Classification  0.036630036630037  0.033088235294118  \n",
      "--------------------------------------------------\n",
      "Database:  Full   LSTM  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  95.41767001152039\n",
      "Accuracy Testing:  94.79584217071533\n",
      "Precision:  96.65138957878816\n",
      "Sensitivity:  92.74482006543076\n",
      "Specificity:  96.780202747586\n",
      "f_1 Score:  94.60563325319565\n",
      "MCC:  89.7279294714158\n",
      "AUC Score:  94.76251140650838\n",
      "MSE:  0.05204158586511528\n",
      "Mis-Classification:  0.05204158586511527\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.958753466606140  0.923006415367126  0.948670923709869   \n",
      "Accuracy Test       0.937728941440582  0.941391944885254  0.926739931106567   \n",
      "Precision           0.984251968503937  0.952755905511811  0.966386554621849   \n",
      "Sensitivity         0.892857142857143  0.923664122137405  0.877862595419847   \n",
      "Specificity         0.984962406015038  0.957746478873239  0.971830985915493   \n",
      "MCC                 0.879663958006727  0.882835526122101  0.856068104735067   \n",
      "AUC Score           0.938909774436090  0.940705300505322  0.924846790667670   \n",
      "f_1 Score           0.936329588014981  0.937984496124031  0.920000000000000   \n",
      "Mis-Classification  0.062271062271062  0.058608058608059  0.073260073260073   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.974335491657257  0.966117203235626  \n",
      "Accuracy Test       0.970695972442627  0.963235318660736  \n",
      "Precision           0.971428571428571  0.957746478873239  \n",
      "Sensitivity         0.971428571428571  0.971428571428571  \n",
      "Specificity         0.969924812030075  0.954545454545455  \n",
      "MCC                 0.941353383458647  0.926475501248248  \n",
      "AUC Score           0.970676691729323  0.962987012987013  \n",
      "f_1 Score           0.971428571428571  0.964539007092199  \n",
      "Mis-Classification  0.029304029304029  0.036764705882353  \n",
      "--------------------------------------------------\n",
      "Database:  Full   CNN  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  96.82908535003662\n",
      "Accuracy Testing:  94.2092227935791\n",
      "Precision:  92.69040411831114\n",
      "Sensitivity:  96.15812431842966\n",
      "Specificity:  92.19976959042934\n",
      "f_1 Score:  94.32171622308465\n",
      "MCC:  88.60125903081378\n",
      "AUC Score:  94.1789469544295\n",
      "MSE:  0.05790777849601379\n",
      "Mis-Classification:  0.057907778496013806\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.974335491657257  0.955087065696716  0.974335491657257   \n",
      "Accuracy Test       0.952380955219269  0.937728941440582  0.945054948329926   \n",
      "Precision           0.950354609929078  0.895833333333333  0.967741935483871   \n",
      "Sensitivity         0.957142857142857  0.984732824427481  0.916030534351145   \n",
      "Specificity         0.947368421052632  0.894366197183099  0.971830985915493   \n",
      "MCC                 0.904705650450487  0.879714024364716  0.890883832169292   \n",
      "AUC Score           0.952255639097744  0.939549510805290  0.943930760133319   \n",
      "f_1 Score           0.953736654804271  0.938181818181818  0.941176470588235   \n",
      "Mis-Classification  0.047619047619048  0.062271062271062  0.054945054945055   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.964253008365631  0.973443210124969  \n",
      "Accuracy Test       0.919413924217224  0.955882370471954  \n",
      "Precision           0.888157894736842  0.932432432432432  \n",
      "Sensitivity         0.964285714285714  0.985714285714286  \n",
      "Specificity         0.872180451127820  0.924242424242424  \n",
      "MCC                 0.841634903573522  0.913124540982671  \n",
      "AUC Score           0.918233082706767  0.954978354978355  \n",
      "f_1 Score           0.924657534246575  0.958333333333333  \n",
      "Mis-Classification  0.080586080586081  0.044117647058823  \n"
     ]
    }
   ],
   "source": [
    "choosen=1 # 0: No Feature, 1: Full\n",
    "\n",
    "db = \"full\" \n",
    "\n",
    "dict_metrics = model_selection(choosen, db)\n",
    "\n",
    "# RF-----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"RF\"], choosen, model_name = \"Random Forest\")\n",
    "\n",
    "# SVM----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"SVM\"], choosen, model_name = \"Support Vector Machine\")\n",
    "\n",
    "# LSTM---------------------------------------------------\n",
    "print_metrics(dict_metrics[\"LSTM\"], choosen, model_name = \"LSTM\")\n",
    "\n",
    "# CNN----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"CNN\"], choosen, model_name = \"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'nf'\n",
    "\n",
    "dict_metrics = { \"RF\" : {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                             'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                  \"SVM\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                          'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                  \"LSTM\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                           'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                  \"CNN\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                          'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},                \n",
    "                }\n",
    "\n",
    "path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "#path_full = 'Databases/Full/full_polarizability.txt'\n",
    "\n",
    "df_model= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "#df_full = pd.read_csv(path_full, sep=\" \", header=None)\n",
    "\n",
    "df_model = change_index(df_model)\n",
    "\n",
    "X, y = build_datasets(df_model)\n",
    "\n",
    "X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model_names = ['rf', 'svm', 'lstm', 'cnn']\n",
    "model_count = 1\n",
    "\n",
    "for model_name in model_names:\n",
    "    for count in range (5):\n",
    "        if model_count<3:\n",
    "            filename = 'SavedModel/'+db+'/'+model_name+'_'+str(count+1)+'.sav'\n",
    "            new_model = pickle.load(open(filename, 'rb'))\n",
    "            \n",
    "            # Testing Accuracy\n",
    "            dict_metrics[model_name.upper()][\"accuracy_train\"].append(0)\n",
    "            dict_metrics[model_name.upper()][\"accuracy_test\"].append(new_model.score(X_testing, y_testing))\n",
    "\n",
    "            # Predicciones\n",
    "            new_predictions = new_model.predict(X_testing)\n",
    "            y_pred = new_predictions\n",
    "            y_t = y_testing\n",
    "\n",
    "            # MSE\n",
    "            dict_metrics[model_name.upper()][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "            # Cálculo de métricas\n",
    "            cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "            precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "            dict_metrics[model_name.upper()][\"precision\"].append(precision)\n",
    "            dict_metrics[model_name.upper()][\"sensitivity\"].append(sensitivity)\n",
    "            dict_metrics[model_name.upper()][\"specificity\"].append(specificity)\n",
    "            dict_metrics[model_name.upper()][\"f1\"].append(conf_f1)\n",
    "            dict_metrics[model_name.upper()][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "            #ROC and AUC Score\n",
    "            auc_score = roc_auc_score(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"auc\"].append(auc_score)\n",
    "\n",
    "            #MCC\n",
    "            mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"mcc\"].append(mcc_score)\n",
    "        else:\n",
    "            filename = 'SavedModel/'+db+'/'+model_name+'_'+str(count+1)+'.h5'\n",
    "            new_model = keras.models.load_model(filename)\n",
    "            \n",
    "            X_test_sequential = np.expand_dims(X_testing, axis=2)\n",
    "            y_test_sequential = to_categorical(y_testing, 2)\n",
    "            \n",
    "            # Testing Accuracy\n",
    "            (_, cnn_acc_test) = new_model.evaluate(X_test_sequential, y_test_sequential, verbose=0)\n",
    "            dict_metrics[model_name.upper()][\"accuracy_train\"].append(0)\n",
    "            dict_metrics[model_name.upper()][\"accuracy_test\"].append(cnn_acc_test)\n",
    "\n",
    "            # Predicciones\n",
    "            new_predictions = new_model.predict(X_test_sequential)\n",
    "            y_pred = np.argmax(new_predictions, axis=1)\n",
    "            y_t = np.argmax(y_test_sequential, axis=1)\n",
    "\n",
    "            # MSE\n",
    "            dict_metrics[model_name.upper()][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "            # Cálculo de métricas\n",
    "            cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "            precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "            dict_metrics[model_name.upper()][\"precision\"].append(precision)\n",
    "            dict_metrics[model_name.upper()][\"sensitivity\"].append(sensitivity)\n",
    "            dict_metrics[model_name.upper()][\"specificity\"].append(specificity)\n",
    "            dict_metrics[model_name.upper()][\"f1\"].append(conf_f1)\n",
    "            dict_metrics[model_name.upper()][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "            #ROC and AUC Score\n",
    "            auc_score = roc_auc_score(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"auc\"].append(auc_score)\n",
    "\n",
    "            #MCC\n",
    "            mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"mcc\"].append(mcc_score)\n",
    "            \n",
    "    model_count = model_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Database:  No Feature   Random Forest  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  96.84210526315789\n",
      "Precision:  97.48417721518987\n",
      "Sensitivity:  96.3157894736842\n",
      "Specificity:  97.36842105263158\n",
      "f_1 Score:  96.84377777947815\n",
      "MCC:  93.79151993466269\n",
      "AUC Score:  96.84210526315789\n",
      "MSE:  0.031578947368421054\n",
      "Mis-Classification:  0.03157894736842104\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.973684210526316  0.953947368421053  0.960526315789474   \n",
      "Precision           1.000000000000000  0.936708860759494  0.937500000000000   \n",
      "Sensitivity         0.947368421052632  0.973684210526316  0.986842105263158   \n",
      "Specificity         1.000000000000000  0.934210526315789  0.934210526315789   \n",
      "MCC                 0.948683298050514  0.908602892483991  0.922330984215777   \n",
      "AUC Score           0.973684210526316  0.953947368421053  0.960526315789474   \n",
      "f_1 Score           0.972972972972973  0.954838709677419  0.961538461538461   \n",
      "Mis-Classification  0.026315789473684  0.046052631578947  0.039473684210526   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.980263157894737  0.973684210526316  \n",
      "Precision           1.000000000000000  1.000000000000000  \n",
      "Sensitivity         0.960526315789474  0.947368421052632  \n",
      "Specificity         1.000000000000000  1.000000000000000  \n",
      "MCC                 0.961275523932339  0.948683298050514  \n",
      "AUC Score           0.980263157894737  0.973684210526316  \n",
      "f_1 Score           0.979865771812081  0.972972972972973  \n",
      "Mis-Classification  0.019736842105263  0.026315789473684  \n",
      "--------------------------------------------------\n",
      "Database:  No Feature   Support Vector Machine  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  96.3157894736842\n",
      "Precision:  100.0\n",
      "Sensitivity:  92.63157894736842\n",
      "Specificity:  100.0\n",
      "f_1 Score:  96.17370235765539\n",
      "MCC:  92.88574066903823\n",
      "AUC Score:  96.3157894736842\n",
      "MSE:  0.03684210526315789\n",
      "Mis-Classification:  0.03684210526315792\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.967105263157895  0.960526315789474  0.960526315789474   \n",
      "Precision           1.000000000000000  1.000000000000000  1.000000000000000   \n",
      "Sensitivity         0.934210526315789  0.921052631578947  0.921052631578947   \n",
      "Specificity         1.000000000000000  1.000000000000000  1.000000000000000   \n",
      "MCC                 0.936238863686262  0.923936435359796  0.923936435359796   \n",
      "AUC Score           0.967105263157895  0.960526315789474  0.960526315789474   \n",
      "f_1 Score           0.965986394557823  0.958904109589041  0.958904109589041   \n",
      "Mis-Classification  0.032894736842105  0.039473684210526  0.039473684210526   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.960526315789474  0.967105263157895  \n",
      "Precision           1.000000000000000  1.000000000000000  \n",
      "Sensitivity         0.921052631578947  0.934210526315789  \n",
      "Specificity         1.000000000000000  1.000000000000000  \n",
      "MCC                 0.923936435359796  0.936238863686262  \n",
      "AUC Score           0.960526315789474  0.967105263157895  \n",
      "f_1 Score           0.958904109589041  0.965986394557823  \n",
      "Mis-Classification  0.039473684210526  0.032894736842105  \n",
      "--------------------------------------------------\n",
      "Database:  No Feature   LSTM  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  94.6052634716034\n",
      "Precision:  95.06567904669171\n",
      "Sensitivity:  94.21052631578948\n",
      "Specificity:  95.0\n",
      "f_1 Score:  94.55218636128933\n",
      "MCC:  89.36466838954162\n",
      "AUC Score:  94.60526315789475\n",
      "MSE:  0.053947368421052626\n",
      "Mis-Classification:  0.05394736842105263\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.934210538864136  0.947368443012238  0.934210538864136   \n",
      "Precision           0.971428571428571  0.925000000000000  0.971428571428571   \n",
      "Sensitivity         0.894736842105263  0.973684210526316  0.894736842105263   \n",
      "Specificity         0.973684210526316  0.921052631578947  0.973684210526316   \n",
      "MCC                 0.871140067624950  0.895978670381041  0.871140067624950   \n",
      "AUC Score           0.934210526315790  0.947368421052632  0.934210526315790   \n",
      "f_1 Score           0.931506849315068  0.948717948717949  0.931506849315068   \n",
      "Mis-Classification  0.065789473684211  0.052631578947368  0.065789473684211   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.953947365283966  0.960526287555695  \n",
      "Precision           0.936708860759494  0.948717948717949  \n",
      "Sensitivity         0.973684210526316  0.973684210526316  \n",
      "Specificity         0.934210526315789  0.947368421052632  \n",
      "MCC                 0.908602892483991  0.921371721362149  \n",
      "AUC Score           0.953947368421053  0.960526315789474  \n",
      "f_1 Score           0.954838709677419  0.961038961038961  \n",
      "Mis-Classification  0.046052631578947  0.039473684210526  \n",
      "--------------------------------------------------\n",
      "Database:  No Feature   CNN  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  96.71052694320679\n",
      "Precision:  99.45164319248826\n",
      "Sensitivity:  93.94736842105263\n",
      "Specificity:  99.47368421052632\n",
      "f_1 Score:  96.60179414026034\n",
      "MCC:  93.5952044306878\n",
      "AUC Score:  96.71052631578947\n",
      "MSE:  0.03289473684210526\n",
      "Mis-Classification:  0.03289473684210527\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.967105269432068  0.953947365283966  0.953947365283966   \n",
      "Precision           1.000000000000000  0.985915492957746  1.000000000000000   \n",
      "Sensitivity         0.934210526315789  0.921052631578947  0.907894736842105   \n",
      "Specificity         1.000000000000000  0.986842105263158  1.000000000000000   \n",
      "MCC                 0.936238863686262  0.909865937948621  0.911770421325905   \n",
      "AUC Score           0.967105263157895  0.953947368421053  0.953947368421053   \n",
      "f_1 Score           0.965986394557823  0.952380952380952  0.951724137931034   \n",
      "Mis-Classification  0.032894736842105  0.046052631578947  0.046052631578947   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.980263173580170  0.980263173580170  \n",
      "Precision           1.000000000000000  0.986666666666667  \n",
      "Sensitivity         0.960526315789474  0.973684210526316  \n",
      "Specificity         1.000000000000000  0.986842105263158  \n",
      "MCC                 0.961275523932339  0.960609474641263  \n",
      "AUC Score           0.980263157894737  0.980263157894737  \n",
      "f_1 Score           0.979865771812081  0.980132450331126  \n",
      "Mis-Classification  0.019736842105263  0.019736842105263  \n"
     ]
    }
   ],
   "source": [
    "choosen=0 # 0: No Feature, 1: Full\n",
    "\n",
    "db = \"nf\" \n",
    "\n",
    "# RF-----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"RF\"], choosen, model_name = \"Random Forest\")\n",
    "\n",
    "# SVM----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"SVM\"], choosen, model_name = \"Support Vector Machine\")\n",
    "\n",
    "# LSTM---------------------------------------------------\n",
    "print_metrics(dict_metrics[\"LSTM\"], choosen, model_name = \"LSTM\")\n",
    "\n",
    "# CNN----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"CNN\"], choosen, model_name = \"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'full'\n",
    "\n",
    "dict_metrics = { \"RF\" : {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                             'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                  \"SVM\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                          'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                  \"LSTM\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                           'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},\n",
    "                  \"CNN\": {'accuracy_train':[], 'accuracy_test':[], 'accuracy_test_ext':[], 'precision':[], 'sensitivity':[], 'specificity':[], \n",
    "                          'f1':[], 'auc':[], 'mcc':[], 'mse':[], 'misc':[]},                \n",
    "                }\n",
    "\n",
    "#path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "path_full = 'Databases/Full/full_polarizability.txt'\n",
    "\n",
    "#df_model= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "df_model = pd.read_csv(path_full, sep=\" \", header=None)\n",
    "\n",
    "df_model = change_index(df_model)\n",
    "\n",
    "X, y = build_datasets(df_model)\n",
    "\n",
    "X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model_names = ['rf', 'svm', 'lstm', 'cnn']\n",
    "model_count = 1\n",
    "\n",
    "for model_name in model_names:\n",
    "    for count in range (5):\n",
    "        if model_count<3:\n",
    "            filename = 'SavedModel/'+db+'/'+model_name+'_'+str(count+1)+'.sav'\n",
    "            new_model = pickle.load(open(filename, 'rb'))\n",
    "            \n",
    "            # Testing Accuracy\n",
    "            dict_metrics[model_name.upper()][\"accuracy_train\"].append(0)\n",
    "            dict_metrics[model_name.upper()][\"accuracy_test\"].append(new_model.score(X_testing, y_testing))\n",
    "\n",
    "            # Predicciones\n",
    "            new_predictions = new_model.predict(X_testing)\n",
    "            y_pred = new_predictions\n",
    "            y_t = y_testing\n",
    "\n",
    "            # MSE\n",
    "            dict_metrics[model_name.upper()][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "            # Cálculo de métricas\n",
    "            cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "            precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "            dict_metrics[model_name.upper()][\"precision\"].append(precision)\n",
    "            dict_metrics[model_name.upper()][\"sensitivity\"].append(sensitivity)\n",
    "            dict_metrics[model_name.upper()][\"specificity\"].append(specificity)\n",
    "            dict_metrics[model_name.upper()][\"f1\"].append(conf_f1)\n",
    "            dict_metrics[model_name.upper()][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "            #ROC and AUC Score\n",
    "            auc_score = roc_auc_score(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"auc\"].append(auc_score)\n",
    "\n",
    "            #MCC\n",
    "            mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"mcc\"].append(mcc_score)\n",
    "        else:\n",
    "            filename = 'SavedModel/'+db+'/'+model_name+'_'+str(count+1)+'.h5'\n",
    "            new_model = keras.models.load_model(filename)\n",
    "            \n",
    "            X_test_sequential = np.expand_dims(X_testing, axis=2)\n",
    "            y_train_sequential = to_categorical(y_testing, 2)\n",
    "            \n",
    "            # Testing Accuracy\n",
    "            (_, cnn_acc_test) = new_model.evaluate(X_test_sequential, y_train_sequential, verbose=0)\n",
    "            dict_metrics[model_name.upper()][\"accuracy_train\"].append(0)\n",
    "            dict_metrics[model_name.upper()][\"accuracy_test\"].append(cnn_acc_test)\n",
    "\n",
    "            # Predicciones\n",
    "            new_predictions = new_model.predict(X_test_sequential)\n",
    "            y_pred = np.argmax(new_predictions, axis=1)\n",
    "            y_t = np.argmax(y_train_sequential, axis=1)\n",
    "\n",
    "            # MSE\n",
    "            dict_metrics[model_name.upper()][\"mse\"].append(mean_squared_error(y_t, y_pred))\n",
    "\n",
    "            # Cálculo de métricas\n",
    "            cm = metrics.confusion_matrix(y_t, y_pred)\n",
    "            precision, sensitivity, specificity, conf_f1, conf_misclassification = confusion_metrics(cm)\n",
    "\n",
    "            dict_metrics[model_name.upper()][\"precision\"].append(precision)\n",
    "            dict_metrics[model_name.upper()][\"sensitivity\"].append(sensitivity)\n",
    "            dict_metrics[model_name.upper()][\"specificity\"].append(specificity)\n",
    "            dict_metrics[model_name.upper()][\"f1\"].append(conf_f1)\n",
    "            dict_metrics[model_name.upper()][\"misc\"].append(conf_misclassification)\n",
    "\n",
    "            #ROC and AUC Score\n",
    "            auc_score = roc_auc_score(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"auc\"].append(auc_score)\n",
    "\n",
    "            #MCC\n",
    "            mcc_score = matthews_corrcoef(y_t, y_pred)\n",
    "            dict_metrics[model_name.upper()][\"mcc\"].append(mcc_score)\n",
    "            \n",
    "    model_count = model_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Database:  Full   Random Forest  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  91.97368421052632\n",
      "Precision:  93.72263993316625\n",
      "Sensitivity:  90.0\n",
      "Specificity:  93.94736842105263\n",
      "f_1 Score:  91.80304752677351\n",
      "MCC:  84.0466850383767\n",
      "AUC Score:  91.97368421052632\n",
      "MSE:  0.08026315789473684\n",
      "Mis-Classification:  0.08026315789473684\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.907894736842105  0.927631578947368  0.921052631578947   \n",
      "Precision           0.942857142857143  0.933333333333333  0.921052631578947   \n",
      "Sensitivity         0.868421052631579  0.921052631578947  0.921052631578947   \n",
      "Specificity         0.947368421052632  0.934210526315789  0.921052631578947   \n",
      "MCC                 0.818343699890105  0.855337203447700  0.842105263157895   \n",
      "AUC Score           0.907894736842105  0.927631578947368  0.921052631578947   \n",
      "f_1 Score           0.904109589041096  0.927152317880795  0.921052631578947   \n",
      "Mis-Classification  0.092105263157895  0.072368421052632  0.078947368421053   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.921052631578947  0.921052631578947  \n",
      "Precision           0.944444444444444  0.944444444444444  \n",
      "Sensitivity         0.894736842105263  0.894736842105263  \n",
      "Specificity         0.947368421052632  0.947368421052632  \n",
      "MCC                 0.843274042711568  0.843274042711568  \n",
      "AUC Score           0.921052631578947  0.921052631578947  \n",
      "f_1 Score           0.918918918918919  0.918918918918919  \n",
      "Mis-Classification  0.078947368421053  0.078947368421053  \n",
      "--------------------------------------------------\n",
      "Database:  Full   Support Vector Machine  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  95.26315789473684\n",
      "Precision:  98.58741336910352\n",
      "Sensitivity:  91.84210526315789\n",
      "Specificity:  98.68421052631578\n",
      "f_1 Score:  95.09264646250948\n",
      "MCC:  90.7427872619553\n",
      "AUC Score:  95.26315789473684\n",
      "MSE:  0.047368421052631574\n",
      "Mis-Classification:  0.047368421052631594\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.947368421052632  0.953947368421053  0.953947368421053   \n",
      "Precision           0.985714285714286  0.985915492957746  0.985915492957746   \n",
      "Sensitivity         0.907894736842105  0.921052631578947  0.921052631578947   \n",
      "Specificity         0.986842105263158  0.986842105263158  0.986842105263158   \n",
      "MCC                 0.897538251492373  0.909865937948621  0.909865937948621   \n",
      "AUC Score           0.947368421052632  0.953947368421053  0.953947368421053   \n",
      "f_1 Score           0.945205479452055  0.952380952380952  0.952380952380952   \n",
      "Mis-Classification  0.052631578947368  0.046052631578947  0.046052631578947   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.947368421052632  0.960526315789474  \n",
      "Precision           0.985714285714286  0.986111111111111  \n",
      "Sensitivity         0.907894736842105  0.934210526315789  \n",
      "Specificity         0.986842105263158  0.986842105263158  \n",
      "MCC                 0.897538251492373  0.922330984215777  \n",
      "AUC Score           0.947368421052632  0.960526315789474  \n",
      "f_1 Score           0.945205479452055  0.959459459459460  \n",
      "Mis-Classification  0.052631578947368  0.039473684210526  \n",
      "--------------------------------------------------\n",
      "Database:  Full   LSTM  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  94.34210538864136\n",
      "Precision:  97.47419333169127\n",
      "Sensitivity:  91.05263157894737\n",
      "Specificity:  97.63157894736841\n",
      "f_1 Score:  94.12018140589569\n",
      "MCC:  88.92721438134011\n",
      "AUC Score:  94.34210526315789\n",
      "MSE:  0.05657894736842105\n",
      "Mis-Classification:  0.05657894736842104\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.934210538864136  0.914473712444305  0.934210538864136   \n",
      "Precision           0.985294117647059  0.943661971830986  0.985294117647059   \n",
      "Sensitivity         0.881578947368421  0.881578947368421  0.881578947368421   \n",
      "Specificity         0.986842105263158  0.947368421052632  0.986842105263158   \n",
      "MCC                 0.873272604641189  0.830747160735697  0.873272604641189   \n",
      "AUC Score           0.934210526315789  0.914473684210526  0.934210526315789   \n",
      "f_1 Score           0.930555555555556  0.911564625850340  0.930555555555556   \n",
      "Mis-Classification  0.065789473684211  0.085526315789474  0.065789473684211   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.973684191703796  0.960526287555695  \n",
      "Precision           0.986486486486487  0.972972972972973  \n",
      "Sensitivity         0.960526315789474  0.947368421052632  \n",
      "Specificity         0.986842105263158  0.973684210526316  \n",
      "MCC                 0.947696627686782  0.921371721362149  \n",
      "AUC Score           0.973684210526316  0.960526315789474  \n",
      "f_1 Score           0.973333333333333  0.960000000000000  \n",
      "Mis-Classification  0.026315789473684  0.039473684210526  \n",
      "--------------------------------------------------\n",
      "Database:  Full   CNN  \n",
      "\n",
      "--------------------------------------------------\n",
      "Model Selection: Onehot | k-mers Sparse Matrix | Autoencoder | (AAC - DPC - PCP)\n",
      "--------------------------------------------------\n",
      "Accuracy Training:  0\n",
      "Accuracy Testing:  93.42105269432068\n",
      "Precision:  91.57982591882575\n",
      "Sensitivity:  95.78947368421052\n",
      "Specificity:  91.05263157894737\n",
      "f_1 Score:  93.5826573402723\n",
      "MCC:  87.04509250602524\n",
      "AUC Score:  93.42105263157895\n",
      "MSE:  0.06578947368421052\n",
      "Mis-Classification:  0.06578947368421051\n",
      "                                    1                  2                  3  \\\n",
      "Accuracy Training   0.000000000000000  0.000000000000000  0.000000000000000   \n",
      "Accuracy Test       0.934210538864136  0.927631556987762  0.940789461135864   \n",
      "Precision           0.923076923076923  0.891566265060241  0.958904109589041   \n",
      "Sensitivity         0.947368421052632  0.973684210526316  0.921052631578947   \n",
      "Specificity         0.921052631578947  0.881578947368421  0.960526315789474   \n",
      "MCC                 0.868721908712883  0.858914165017157  0.882266576759818   \n",
      "AUC Score           0.934210526315789  0.927631578947368  0.940789473684211   \n",
      "f_1 Score           0.935064935064935  0.930817610062893  0.939597315436242   \n",
      "Mis-Classification  0.065789473684211  0.072368421052632  0.059210526315789   \n",
      "\n",
      "                                    4                  5  \n",
      "Accuracy Training   0.000000000000000  0.000000000000000  \n",
      "Accuracy Test       0.914473712444305  0.953947365283966  \n",
      "Precision           0.879518072289157  0.925925925925926  \n",
      "Sensitivity         0.960526315789474  0.986842105263158  \n",
      "Specificity         0.868421052631579  0.921052631578947  \n",
      "MCC                 0.832486036862783  0.909865937948621  \n",
      "AUC Score           0.914473684210526  0.953947368421053  \n",
      "f_1 Score           0.918238993710692  0.955414012738854  \n",
      "Mis-Classification  0.085526315789474  0.046052631578947  \n"
     ]
    }
   ],
   "source": [
    "choosen=1 # 0: No Feature, 1: Full\n",
    "\n",
    "# RF-----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"RF\"], choosen, model_name = \"Random Forest\")\n",
    "\n",
    "# SVM----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"SVM\"], choosen, model_name = \"Support Vector Machine\")\n",
    "\n",
    "# LSTM---------------------------------------------------\n",
    "print_metrics(dict_metrics[\"LSTM\"], choosen, model_name = \"LSTM\")\n",
    "\n",
    "# CNN----------------------------------------------------\n",
    "print_metrics(dict_metrics[\"CNN\"], choosen, model_name = \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=2, max_features=2,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=True, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(max_depth=2, max_features=2, min_samples_split = 10, min_samples_leaf = 2, bootstrap=True, oob_score=True,criterion='entropy',random_state = 42, n_jobs=-1)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993421052631579"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "train = []\n",
    "test_ext = []\n",
    "mse = []\n",
    "path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "\n",
    "df_nf= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "\n",
    "df_model = df_nf\n",
    "\n",
    "df_model = change_index(df_model)\n",
    "\n",
    "X, y = build_datasets(df_model)\n",
    "\n",
    "X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "y_main = y_main.to_numpy()\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "kf.get_n_splits(X_main)\n",
    "\n",
    "for train_index, test_index in kf.split(X_main):\n",
    "\n",
    "    X_train, X_test = X_main[train_index], X_main[test_index]\n",
    "    y_train, y_test = y_main[train_index], y_main[test_index]\n",
    "    \n",
    "    #model_rf = RandomForestClassifier(max_depth=2, max_features=2, min_samples_split = 10, min_samples_leaf = 2, bootstrap=True, oob_score=True,criterion='entropy',random_state = 42, n_jobs=-1)\n",
    "    model_rf = RandomForestClassifier(max_depth=2, max_features=2, random_state = 42)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    \n",
    "    train.append(model_rf.score(X_train, y_train))\n",
    "    test.append(model_rf.score(X_test, y_test))\n",
    "    test_ext.append(model_rf.score(X_testing, y_testing))\n",
    "    \n",
    "    # Predicciones\n",
    "    new_predictions = model_rf.predict(X_test)\n",
    "    y_pred = new_predictions\n",
    "    y_t = y_test\n",
    "    \n",
    "    #print(y_pred.shape, y_t.shape)\n",
    "    \n",
    "    # MSE\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse.append(mean_squared_error(y_t, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9785566556877281, 0.9648028442146089, 0.968421052631579)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(train), statistics.mean(test), statistics.mean(test_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "train = []\n",
    "test_ext = []\n",
    "path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "\n",
    "df_nf= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "\n",
    "df_model = df_nf\n",
    "\n",
    "df_model = change_index(df_model)\n",
    "\n",
    "X, y = build_datasets(df_model)\n",
    "\n",
    "X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "y_main = y_main.to_numpy()\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "kf.get_n_splits(X_main)\n",
    "\n",
    "for train_index, test_index in kf.split(X_main):\n",
    "\n",
    "    X_train, X_test = X_main[train_index], X_main[test_index]\n",
    "    y_train, y_test = y_main[train_index], y_main[test_index]\n",
    "    \n",
    "    #model_rf = RandomForestClassifier(max_depth=2, max_features=2, min_samples_split = 10, min_samples_leaf = 2, bootstrap=True, oob_score=True,criterion='entropy',random_state = 42, n_jobs=-1)\n",
    "    #model_svm = svm.SVC(kernel='poly', C=10, degree=10, gamma='auto', probability=True,verbose = False) # Linear Kernel\n",
    "    model_svm = svm.SVC(kernel='rbf', gamma='auto', C=1, verbose = False) # Linear Kernel\n",
    "    model_svm.fit(X_train, y_train)\n",
    "    \n",
    "    train.append(model_svm.score(X_train, y_train))\n",
    "    test.append(model_svm.score(X_test, y_test))\n",
    "    test_ext.append(model_svm.score(X_testing, y_testing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9684847015729369, 0.9631578947368421)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(train), statistics.mean(test), statistics.mean(test_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "train = []\n",
    "test_ext = []\n",
    "path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "\n",
    "df_nf= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "\n",
    "df_model = df_nf\n",
    "\n",
    "df_model = change_index(df_model)\n",
    "\n",
    "X, y = build_datasets(df_model)\n",
    "\n",
    "X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_testing_lstm = np.expand_dims(X_testing, axis=2)\n",
    "y_testing_lstm = to_categorical(y_testing, 2)\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "kf.get_n_splits(X_main)\n",
    "\n",
    "for train_index, test_index in kf.split(X_main):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train_lstm = np.expand_dims(X_train, axis=2)\n",
    "    X_test_lstm = np.expand_dims(X_test, axis=2)\n",
    "    y_train_lstm = to_categorical(y_train, 2)\n",
    "    y_test_lstm = to_categorical(y_test, 2)\n",
    "\n",
    "    n_timesteps, n_features, n_outputs = X_train_lstm.shape[0], X_train_lstm.shape[1], y_train_lstm.shape[1]\n",
    "    input_shape = (n_features,1)\n",
    "\n",
    "    model_lstm = create_model_lstm(input_shape, n_outputs)\n",
    "    model_lstm.fit(X_train_lstm,y_train_lstm,verbose=0)\n",
    "    \n",
    "    (_, lstm_accuracy) = model_lstm.evaluate(X_train_lstm, y_train_lstm, verbose=0)\n",
    "    train.append(lstm_accuracy)\n",
    "    \n",
    "    (_, lstm_accuracy) = model_lstm.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "    test.append(lstm_accuracy)\n",
    "    \n",
    "    (_, lstm_accuracy) = model_lstm.evaluate(X_testing_lstm, y_testing_lstm, verbose=0)\n",
    "    test_ext.append(lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9373193264007569, 0.9347500562667846, 0.9407894849777222)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(train), statistics.mean(test), statistics.mean(test_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "train = []\n",
    "test_ext = []\n",
    "path_nf = 'Databases/NoFeature/nf_polarizability.txt'\n",
    "\n",
    "df_nf= pd.read_csv(path_nf, sep=\" \", header=None)\n",
    "\n",
    "df_model = df_nf\n",
    "\n",
    "df_model = change_index(df_model)\n",
    "\n",
    "X, y = build_datasets(df_model)\n",
    "\n",
    "X_main, X_testing, y_main, y_testing = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "y_main = y_main.to_numpy()\n",
    "\n",
    "X_testing_cnn = np.expand_dims(X_testing, axis=2)\n",
    "y_testing_cnn = to_categorical(y_testing, 2)\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "kf.get_n_splits(X_main)\n",
    "\n",
    "for train_index, test_index in kf.split(X_main):\n",
    "\n",
    "    X_train, X_test = X_main[train_index], X_main[test_index]\n",
    "    y_train, y_test = y_main[train_index], y_main[test_index]\n",
    "    \n",
    "    X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "    X_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "    y_train_cnn = to_categorical(y_train, 2)\n",
    "    y_test_cnn = to_categorical(y_test, 2)\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = X_train_cnn.shape[0], X_train_cnn.shape[1], y_train_cnn.shape[1]\n",
    "    input_shape = (n_features,1)\n",
    "\n",
    "    model_cnn = create_model_cnn(input_shape, n_outputs)\n",
    "    model_cnn.fit(X_train_cnn,y_train_cnn,batch_size=150,verbose=0)\n",
    "    \n",
    "    (_, cnn_accuracy) = model_cnn.evaluate(X_train_cnn, y_train_cnn, verbose=0)\n",
    "    train.append(cnn_accuracy)\n",
    "    \n",
    "    (_, cnn_accuracy) = model_cnn.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "    test.append(cnn_accuracy)\n",
    "    \n",
    "    (_, cnn_accuracy) = model_cnn.evaluate(X_testing_cnn, y_testing_cnn, verbose=0)\n",
    "    test_ext.append(cnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9871705889701843, 0.9692146062850953, 0.967105257511139)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(train), statistics.mean(test), statistics.mean(test_ext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
